{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e718041c",
   "metadata": {},
   "source": [
    "# 1_Setup_and_Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f056607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports are successful ✅\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Python version: 3.12.11 | packaged by Anaconda, Inc. | (main, Jun  5 2025, 13:09:17) [GCC 11.2.0]\n",
      "Pip version: 25.1\n",
      "Pytorch version: 2.7.0+cu126\n",
      "CUDA version: 12.6\n",
      "GPU is available.\n",
      "Number of GPUs: 2\n",
      "GPU 0: NVIDIA GeForce RTX 4070\n",
      "GPU 1: NVIDIA GeForce RTX 4070\n",
      "Pytorch can use CUDA ✅Tensor on GPU\n"
     ]
    }
   ],
   "source": [
    "# All imports\n",
    "import sys\n",
    "import pip\n",
    "import torch\n",
    "from datasets import get_dataset_split_names, load_dataset, load_dataset_builder, get_dataset_config_names\n",
    "from transformers import pipeline\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, MBart50Tokenizer, MBartForConditionalGeneration\n",
    "\n",
    "print(\"All imports are successful ✅\")\n",
    "\n",
    "print(\"--\" * 50)\n",
    "\n",
    "#---------------------------------------------------------------\n",
    "# Check Python, pip, and pytorch versions and cuda compatibility\n",
    "#---------------------------------------------------------------\n",
    "print(\"Python version:\", sys.version)\n",
    "# Print pip version\n",
    "print(\"Pip version:\", pip.__version__)\n",
    "# Print pytorch version\n",
    "print(\"Pytorch version:\", torch.__version__)\n",
    "# Print CUDA version\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA version:\", torch.version.cuda)\n",
    "else:\n",
    "    print(\"CUDA is not available.\")\n",
    "\n",
    "# Print GPU information\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is available.\")\n",
    "    print(\"Number of GPUs:\", torch.cuda.device_count())\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "else:\n",
    "    print(\"No GPU available.\")\n",
    "\n",
    "# Check if pytorch can use CUDA\n",
    "if torch.cuda.is_available():\n",
    "    x = torch.rand(5, 3).cuda()\n",
    "    if x.is_cuda:\n",
    "        print(\"Pytorch can use CUDA ✅Tensor on GPU\")\n",
    "else:\n",
    "    print(\"Pytorch is not using CUDA.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30206b71",
   "metadata": {},
   "source": [
    "# 2_Load_Dataset_and_Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80dbfe1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available dataset splits: ['train', 'validation', 'test']\n",
      "Available dataset configurations: ['Itihasa']\n"
     ]
    }
   ],
   "source": [
    "# https://huggingface.co/docs/datasets/load_hub\n",
    "splits = get_dataset_split_names(\"rahular/itihasa\")\n",
    "print(\"Available dataset splits:\", splits)\n",
    "configs = get_dataset_config_names(\"rahular/itihasa\")\n",
    "print(\"Available dataset configurations:\", configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec7db925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'translation': Translation(languages=['sn', 'en'], id=None)}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_builder = load_dataset_builder(\"rahular/itihasa\")\n",
    "\n",
    "# Inspect dataset description\n",
    "ds_builder.info.description\n",
    "\n",
    "# Inspect dataset features\n",
    "ds_builder.info.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dafb5cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets loaded successfully ✅.\n",
      "Train dataset size: 75162\n",
      "Validation dataset size: 6149\n",
      "Test dataset size: 11722\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "train_dataset = load_dataset(\"rahular/itihasa\", split=\"train\")\n",
    "valid_dataset = load_dataset(\"rahular/itihasa\", split=\"validation\")\n",
    "test_dataset  = load_dataset(\"rahular/itihasa\", split=\"test\")\n",
    "print(\"Datasets loaded successfully ✅.\")\n",
    "\n",
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Validation dataset size: {len(valid_dataset)}\")\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb1a17ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'translation': {'en': 'The ascetic Vālmīki asked Nārada, the best of sages and foremost of those conversant with words, ever engaged in austerities and Vedic studies.',\n",
       "  'sn': 'ॐ तपः स्वाध्यायनिरतं तपस्वी वाग्विदां वरम्। नारदं परिपप्रच्छ वाल्मीकिर्मुनिपुङ्गवम्॥'}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]  # Inspect the first example in the train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "195509c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'translation': {'en': 'Hearing the words of Viśvāmitra, Rāghava, together with Laksmana, was struck with amazement, and spoke to Viśvāmitra, saying,',\n",
       "  'sn': 'विश्वामित्रवचः श्रुत्वा राघवः सहलक्ष्मणः। विस्मयं परमं गत्वा विश्वामित्रमथाब्रवीत्॥'}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[0]  # Inspect the first example in the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c896d07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'translation': {'en': 'When Şītā, having a husband although seeming as if she had none, was putting on the ascetic guise, the people got into a wrath and exclaimed, “O Dasaratha, fie on you!\"',\n",
       "  'sn': 'तस्यां चीरं वसानायां नाथवत्यामनाथवत्। प्रचुक्रोश जनः सर्वो धिक् त्वां दशरथं त्विति ॥'}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_dataset[0] # Inspect the first example in the validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e8a56f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'translation': {'en': 'The ascetic Vālmīki asked Nārada, the best of sages and foremost of those conversant with words, ever engaged in austerities and Vedic studies.', 'sn': 'ॐ तपः स्वाध्यायनिरतं तपस्वी वाग्विदां वरम्। नारदं परिपप्रच्छ वाल्मीकिर्मुनिपुङ्गवम्॥'}}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'en': 'The ascetic Vālmīki asked Nārada, the best of sages and foremost of those conversant with words, ever engaged in austerities and Vedic studies.', 'sn': 'ॐ तपः स्वाध्यायनिरतं तपस्वी वाग्विदां वरम्। नारदं परिपप्रच्छ वाल्मीकिर्मुनिपुङ्गवम्॥'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "The ascetic Vālmīki asked Nārada, the best of sages and foremost of those conversant with words, ever engaged in austerities and Vedic studies.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ॐ तपः स्वाध्यायनिरतं तपस्वी वाग्विदां वरम्। नारदं परिपप्रच्छ वाल्मीकिर्मुनिपुङ्गवम्॥\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Example 0: (English: The ascetic Vālmīki asked Nārada, the best of sages and foremost of those conversant with words, ever engaged in austerities and Vedic studies.) (Sanskrit: ॐ तपः स्वाध्यायनिरतं तपस्वी वाग्विदां वरम्। नारदं परिपप्रच्छ वाल्मीकिर्मुनिपुङ्गवम्॥)\n",
      "Example 1: (English: Who at present in this world is like crowned with qualities, and with prowess, knowing duty, and grateful, and truthful, and firm in vow.) (Sanskrit: कोन्वस्मिन् साम्प्रतं लोके गुणवान् कश्च वीर्यवान्। धर्मज्ञश्च कृतज्ञश्च सत्यवाक्यो दृढत्नतः॥)\n",
      "Example 2: (English: Who is qualified by virtue of his character, and who is engaged in the welfare of all creatures? Who is learned and capable. Who alone is ever lovely to behold?) (Sanskrit: चारित्रेण च को युक्तः सर्वभूतेषु को हितः। विद्वान् कः कः समर्थश्च कश्चैकप्रियदर्शनः॥)\n"
     ]
    }
   ],
   "source": [
    "# Indexing the datasets\n",
    "print(train_dataset[0])  # To see the full content of the first example\n",
    "print(\"--\" * 50)\n",
    "print(train_dataset[0][\"translation\"])  # To see the root of the nested dictionary\n",
    "print(\"--\" * 50)\n",
    "print(train_dataset[0][\"translation\"][\"en\"])  # To see the English translation of the first example\n",
    "print(\"--\" * 50)\n",
    "print(train_dataset[0][\"translation\"][\"sn\"])  # To see the Sanskrit translation of the first example\n",
    "print(\"--\" * 50)\n",
    "for i in range(3):\n",
    "    print(f\"Example {i}: (English: {train_dataset[i]['translation']['en']}) (Sanskrit: {train_dataset[i]['translation']['sn']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5cd3a6",
   "metadata": {},
   "source": [
    "# 3_Modelling_and_Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ab90b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "20f1cbca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n"
     ]
    }
   ],
   "source": [
    "model = MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n",
    "tokenizer = MBart50Tokenizer.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n",
    "\n",
    "tokenizer.src_lang = \"en_XX\"\n",
    "tokenizer.tgt_lang = \"hi_IN\"  # Set source and target languages\n",
    "\n",
    "text = \".\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "# Force decoder to use target language\n",
    "output_ids = model.generate(\n",
    "    **inputs,\n",
    "    forced_bos_token_id=tokenizer.lang_code_to_id[tokenizer.tgt_lang]\n",
    ")\n",
    "\n",
    "print(tokenizer.decode(output_ids[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7a363e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ar_AR': 250001,\n",
       " 'cs_CZ': 250002,\n",
       " 'de_DE': 250003,\n",
       " 'en_XX': 250004,\n",
       " 'es_XX': 250005,\n",
       " 'et_EE': 250006,\n",
       " 'fi_FI': 250007,\n",
       " 'fr_XX': 250008,\n",
       " 'gu_IN': 250009,\n",
       " 'hi_IN': 250010,\n",
       " 'it_IT': 250011,\n",
       " 'ja_XX': 250012,\n",
       " 'kk_KZ': 250013,\n",
       " 'ko_KR': 250014,\n",
       " 'lt_LT': 250015,\n",
       " 'lv_LV': 250016,\n",
       " 'my_MM': 250017,\n",
       " 'ne_NP': 250018,\n",
       " 'nl_XX': 250019,\n",
       " 'ro_RO': 250020,\n",
       " 'ru_RU': 250021,\n",
       " 'si_LK': 250022,\n",
       " 'tr_TR': 250023,\n",
       " 'vi_VN': 250024,\n",
       " 'zh_CN': 250025,\n",
       " 'af_ZA': 250026,\n",
       " 'az_AZ': 250027,\n",
       " 'bn_IN': 250028,\n",
       " 'fa_IR': 250029,\n",
       " 'he_IL': 250030,\n",
       " 'hr_HR': 250031,\n",
       " 'id_ID': 250032,\n",
       " 'ka_GE': 250033,\n",
       " 'km_KH': 250034,\n",
       " 'mk_MK': 250035,\n",
       " 'ml_IN': 250036,\n",
       " 'mn_MN': 250037,\n",
       " 'mr_IN': 250038,\n",
       " 'pl_PL': 250039,\n",
       " 'ps_AF': 250040,\n",
       " 'pt_XX': 250041,\n",
       " 'sv_SE': 250042,\n",
       " 'sw_KE': 250043,\n",
       " 'ta_IN': 250044,\n",
       " 'te_IN': 250045,\n",
       " 'th_TH': 250046,\n",
       " 'tl_XX': 250047,\n",
       " 'uk_UA': 250048,\n",
       " 'ur_PK': 250049,\n",
       " 'xh_ZA': 250050,\n",
       " 'gl_ES': 250051,\n",
       " 'sl_SI': 250052}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check total\n",
    "tokenizer.lang_code_to_id\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ashtra_mind",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
