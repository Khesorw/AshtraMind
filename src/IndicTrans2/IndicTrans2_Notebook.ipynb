{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Khesorw/AshtraMind/blob/main/IndicTrans2_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ax5UlPwtJXc_"
      },
      "outputs": [],
      "source": [
        "# !pip install transformers sentencepiece evaluate accelerate\n",
        "# !pip install datasets==3.6.0\n",
        "# !pip install rouge_score\n",
        "# !pip install sacrebleu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "coN8VVHzKTOX"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4e5df6858c544f4cabbd94048163043e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fc9482bfd59c488a8253d2a564d7fb86",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenization_indictrans.py: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "A new version of the following files was downloaded from https://huggingface.co/ai4bharat/indictrans2-en-indic-dist-200M:\n",
            "- tokenization_indictrans.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "97fb08e7322e45a7928100df6ed660cd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "dict.SRC.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d26f878e52bc4cf4b32c5692d91616d3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "dict.TGT.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cbc4fde46a72487ebdb7fb625f456ce7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.SRC:   0%|          | 0.00/759k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4da802dcf74f4deebea67675b6a69b9d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.TGT:   0%|          | 0.00/3.26M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "19eaa24c910447f79ff30ea67a633f89",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/96.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "06dbd4b8bc16481d8b0a484a25cd3d78",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "104453d5a74d46f49e1bed82d4f9c761",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "configuration_indictrans.py: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "A new version of the following files was downloaded from https://huggingface.co/ai4bharat/indictrans2-en-indic-dist-200M:\n",
            "- configuration_indictrans.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9cc7e0378ec242598527c74f755362cf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "modeling_indictrans.py: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "A new version of the following files was downloaded from https://huggingface.co/ai4bharat/indictrans2-en-indic-dist-200M:\n",
            "- modeling_indictrans.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2ff5fbd97d34494aabba3dbd1040bfbb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.10G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "14e9720112ac4674b8b5eab59c97c057",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/163 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "📊 IndicTrans2-small on Itihāsa Test Set:\n",
            "BLEU:     0.0002\n",
            "ROUGE-1:  0.0000\n",
            "ROUGE-2:  0.0000\n",
            "ROUGE-L:  0.0000\n",
            "chrF++:   23.6763\n",
            "\n",
            "🔍 Sample translations:\n",
            "\n",
            "SRC:  Hearing the words of Viśvāmitra, Rāghava, together with Laksmana, was struck with amazement, and spoke to Viśvāmitra, saying,\n",
            "PRED: लक्ष्मणेन सह, विश्वामित्ररघवस्य वचनानि श्रुत्वा, सः विस्मितः भूत्वा, विश्वामित्रेन सह उक्तवान् ।\n",
            "REF:  विश्वामित्रवचः श्रुत्वा राघवः सहलक्ष्मणः। विस्मयं परमं गत्वा विश्वामित्रमथाब्रवीत्॥\n",
            "\n",
            "SRC:  O Brāhmaṇa, wonderful is the story that you have recited to us, viz; that of Ganga's sacred dissension and the replenishing of the Ocean.\n",
            "PRED: हे ब्राह्मणः अद्भुतः कथा अस्ति या भवान् गङ्गायाः पवित्रविवेचनस्य, समुद्रस्य पुनर्भरणस्य च कथां पठितवान् ।\n",
            "REF:  अत्यद्भुतमिदं ब्रह्मन् कथितं परमं त्वया। गङ्गावतरणं पुण्यं सागरस्यापि पूरणम्॥\n",
            "\n",
            "SRC:  And, O afflicter of foes, as we had been reflecting upon all this at length, the night has passed away as if it were as moment.\n",
            "PRED: हे शत्रूनां पीडितः, यतोहि वयं एतस्मिन् विषये दीर्घकालं चिन्तयामः, तत् रात्रिः क्षणस्य इव गतवती ।\n",
            "REF:  क्षणभूतेव नौ रात्रिः संवृत्तेयं परंतप। इमां चिन्तयतोः सर्वा निखिलेन कथां तव॥\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "from datasets import load_dataset\n",
        "import evaluate\n",
        "\n",
        "# Load test dataset\n",
        "ds = load_dataset(\"rahular/itihasa\", split=\"test\")\n",
        "src_texts_raw = [ex[\"translation\"][\"en\"] for ex in ds]\n",
        "tgt_texts = [ex[\"translation\"][\"sn\"] for ex in ds]\n",
        "\n",
        "# Language tags required by IndicTrans2\n",
        "src_lang_tag = \"eng_Latn\"\n",
        "tgt_lang_tag = \"san_Deva\"\n",
        "\n",
        "# Prepend language tags to source text\n",
        "src_texts = [f\"{src_lang_tag} {tgt_lang_tag} {text}\" for text in src_texts_raw]\n",
        "\n",
        "# Load tokenizer and model\n",
        "model_name = \"ai4bharat/indictrans2-en-indic-dist-200M\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name, trust_remote_code=True)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# Load evaluation metrics\n",
        "bleu = evaluate.load(\"bleu\")\n",
        "rouge = evaluate.load(\"rouge\")\n",
        "chrf = evaluate.load(\"chrf\")\n",
        "\n",
        "# Translation function\n",
        "def translate_batch(texts, max_length=128):\n",
        "    inputs = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=max_length)\n",
        "    inputs = inputs.to(model.device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(**inputs,use_cache=False, max_length=max_length, num_beams=5)\n",
        "    return tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "\n",
        "# Batched translation\n",
        "all_preds, all_refs = [], []\n",
        "batch_size = 16\n",
        "\n",
        "for i in range(0, len(src_texts), batch_size):\n",
        "    batch_src = src_texts[i:i + batch_size]\n",
        "    batch_ref = tgt_texts[i:i + batch_size]\n",
        "\n",
        "    preds = translate_batch(batch_src)\n",
        "    all_preds.extend(preds)\n",
        "    all_refs.extend([[ref] for ref in batch_ref])\n",
        "\n",
        "# Strip whitespace\n",
        "all_preds = [p.strip() for p in all_preds]\n",
        "all_refs_flat = [ref[0].strip() for ref in all_refs]\n",
        "\n",
        "# Compute metrics\n",
        "bleu_score = bleu.compute(predictions=all_preds, references=all_refs)[\"bleu\"]\n",
        "rouge_score = rouge.compute(predictions=all_preds, references=all_refs_flat)\n",
        "chrf_score = chrf.compute(predictions=all_preds, references=all_refs_flat)\n",
        "\n",
        "# Results\n",
        "print(\"\\n📊 IndicTrans2-small on Itihāsa Test Set:\")\n",
        "print(f\"BLEU:     {bleu_score:.4f}\")\n",
        "print(f\"ROUGE-1:  {rouge_score['rouge1']:.4f}\")\n",
        "print(f\"ROUGE-2:  {rouge_score['rouge2']:.4f}\")\n",
        "print(f\"ROUGE-L:  {rouge_score['rougeL']:.4f}\")\n",
        "print(f\"chrF++:   {chrf_score['score']:.4f}\")\n",
        "\n",
        "# Sample outputs\n",
        "print(\"\\n🔍 Sample translations:\")\n",
        "for src, ref, pred in zip(src_texts_raw[:3], all_refs_flat[:3], all_preds[:3]):\n",
        "    print(f\"\\nSRC:  {src}\")\n",
        "    print(f\"PRED: {pred}\")\n",
        "    print(f\"REF:  {ref}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'translation': Translation(languages=['sn', 'en'], id=None)}\n",
            "{'en': 'Hearing the words of Viśvāmitra, Rāghava, together with Laksmana, was struck with amazement, and spoke to Viśvāmitra, saying,', 'sn': 'विश्वामित्रवचः श्रुत्वा राघवः सहलक्ष्मणः। विस्मयं परमं गत्वा विश्वामित्रमथाब्रवीत्॥'}\n"
          ]
        }
      ],
      "source": [
        "print(ds.features)\n",
        "print(ds[0][\"translation\"])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyM+6Jg+2u6YFIgYlVUU8n3Q",
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ashtra_mind",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
