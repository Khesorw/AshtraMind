{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Khesorw/AshtraMind/blob/main/IndicTrans2_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ax5UlPwtJXc_"
      },
      "outputs": [],
      "source": [
        "# !pip install transformers sentencepiece evaluate accelerate\n",
        "# !pip install datasets==3.6.0\n",
        "# !pip install rouge_score\n",
        "# !pip install sacrebleu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "coN8VVHzKTOX"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4e5df6858c544f4cabbd94048163043e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fc9482bfd59c488a8253d2a564d7fb86",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenization_indictrans.py: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "A new version of the following files was downloaded from https://huggingface.co/ai4bharat/indictrans2-en-indic-dist-200M:\n",
            "- tokenization_indictrans.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "97fb08e7322e45a7928100df6ed660cd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "dict.SRC.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d26f878e52bc4cf4b32c5692d91616d3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "dict.TGT.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cbc4fde46a72487ebdb7fb625f456ce7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.SRC:   0%|          | 0.00/759k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4da802dcf74f4deebea67675b6a69b9d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.TGT:   0%|          | 0.00/3.26M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "19eaa24c910447f79ff30ea67a633f89",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/96.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "06dbd4b8bc16481d8b0a484a25cd3d78",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "104453d5a74d46f49e1bed82d4f9c761",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "configuration_indictrans.py: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "A new version of the following files was downloaded from https://huggingface.co/ai4bharat/indictrans2-en-indic-dist-200M:\n",
            "- configuration_indictrans.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9cc7e0378ec242598527c74f755362cf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "modeling_indictrans.py: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "A new version of the following files was downloaded from https://huggingface.co/ai4bharat/indictrans2-en-indic-dist-200M:\n",
            "- modeling_indictrans.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2ff5fbd97d34494aabba3dbd1040bfbb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.10G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "14e9720112ac4674b8b5eab59c97c057",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/163 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ðŸ“Š IndicTrans2-small on ItihÄsa Test Set:\n",
            "BLEU:     0.0002\n",
            "ROUGE-1:  0.0000\n",
            "ROUGE-2:  0.0000\n",
            "ROUGE-L:  0.0000\n",
            "chrF++:   23.6763\n",
            "\n",
            "ðŸ” Sample translations:\n",
            "\n",
            "SRC:  Hearing the words of ViÅ›vÄmitra, RÄghava, together with Laksmana, was struck with amazement, and spoke to ViÅ›vÄmitra, saying,\n",
            "PRED: à¤²à¤•à¥à¤·à¥à¤®à¤£à¥‡à¤¨ à¤¸à¤¹, à¤µà¤¿à¤¶à¥à¤µà¤¾à¤®à¤¿à¤¤à¥à¤°à¤°à¤˜à¤µà¤¸à¥à¤¯ à¤µà¤šà¤¨à¤¾à¤¨à¤¿ à¤¶à¥à¤°à¥à¤¤à¥à¤µà¤¾, à¤¸à¤ƒ à¤µà¤¿à¤¸à¥à¤®à¤¿à¤¤à¤ƒ à¤­à¥‚à¤¤à¥à¤µà¤¾, à¤µà¤¿à¤¶à¥à¤µà¤¾à¤®à¤¿à¤¤à¥à¤°à¥‡à¤¨ à¤¸à¤¹ à¤‰à¤•à¥à¤¤à¤µà¤¾à¤¨à¥ à¥¤\n",
            "REF:  à¤µà¤¿à¤¶à¥à¤µà¤¾à¤®à¤¿à¤¤à¥à¤°à¤µà¤šà¤ƒ à¤¶à¥à¤°à¥à¤¤à¥à¤µà¤¾ à¤°à¤¾à¤˜à¤µà¤ƒ à¤¸à¤¹à¤²à¤•à¥à¤·à¥à¤®à¤£à¤ƒà¥¤ à¤µà¤¿à¤¸à¥à¤®à¤¯à¤‚ à¤ªà¤°à¤®à¤‚ à¤—à¤¤à¥à¤µà¤¾ à¤µà¤¿à¤¶à¥à¤µà¤¾à¤®à¤¿à¤¤à¥à¤°à¤®à¤¥à¤¾à¤¬à¥à¤°à¤µà¥€à¤¤à¥à¥¥\n",
            "\n",
            "SRC:  O BrÄhmaá¹‡a, wonderful is the story that you have recited to us, viz; that of Ganga's sacred dissension and the replenishing of the Ocean.\n",
            "PRED: à¤¹à¥‡ à¤¬à¥à¤°à¤¾à¤¹à¥à¤®à¤£à¤ƒ à¤…à¤¦à¥à¤­à¥à¤¤à¤ƒ à¤•à¤¥à¤¾ à¤…à¤¸à¥à¤¤à¤¿ à¤¯à¤¾ à¤­à¤µà¤¾à¤¨à¥ à¤—à¤™à¥à¤—à¤¾à¤¯à¤¾à¤ƒ à¤ªà¤µà¤¿à¤¤à¥à¤°à¤µà¤¿à¤µà¥‡à¤šà¤¨à¤¸à¥à¤¯, à¤¸à¤®à¥à¤¦à¥à¤°à¤¸à¥à¤¯ à¤ªà¥à¤¨à¤°à¥à¤­à¤°à¤£à¤¸à¥à¤¯ à¤š à¤•à¤¥à¤¾à¤‚ à¤ªà¤ à¤¿à¤¤à¤µà¤¾à¤¨à¥ à¥¤\n",
            "REF:  à¤…à¤¤à¥à¤¯à¤¦à¥à¤­à¥à¤¤à¤®à¤¿à¤¦à¤‚ à¤¬à¥à¤°à¤¹à¥à¤®à¤¨à¥ à¤•à¤¥à¤¿à¤¤à¤‚ à¤ªà¤°à¤®à¤‚ à¤¤à¥à¤µà¤¯à¤¾à¥¤ à¤—à¤™à¥à¤—à¤¾à¤µà¤¤à¤°à¤£à¤‚ à¤ªà¥à¤£à¥à¤¯à¤‚ à¤¸à¤¾à¤—à¤°à¤¸à¥à¤¯à¤¾à¤ªà¤¿ à¤ªà¥‚à¤°à¤£à¤®à¥à¥¥\n",
            "\n",
            "SRC:  And, O afflicter of foes, as we had been reflecting upon all this at length, the night has passed away as if it were as moment.\n",
            "PRED: à¤¹à¥‡ à¤¶à¤¤à¥à¤°à¥‚à¤¨à¤¾à¤‚ à¤ªà¥€à¤¡à¤¿à¤¤à¤ƒ, à¤¯à¤¤à¥‹à¤¹à¤¿ à¤µà¤¯à¤‚ à¤à¤¤à¤¸à¥à¤®à¤¿à¤¨à¥ à¤µà¤¿à¤·à¤¯à¥‡ à¤¦à¥€à¤°à¥à¤˜à¤•à¤¾à¤²à¤‚ à¤šà¤¿à¤¨à¥à¤¤à¤¯à¤¾à¤®à¤ƒ, à¤¤à¤¤à¥ à¤°à¤¾à¤¤à¥à¤°à¤¿à¤ƒ à¤•à¥à¤·à¤£à¤¸à¥à¤¯ à¤‡à¤µ à¤—à¤¤à¤µà¤¤à¥€ à¥¤\n",
            "REF:  à¤•à¥à¤·à¤£à¤­à¥‚à¤¤à¥‡à¤µ à¤¨à¥Œ à¤°à¤¾à¤¤à¥à¤°à¤¿à¤ƒ à¤¸à¤‚à¤µà¥ƒà¤¤à¥à¤¤à¥‡à¤¯à¤‚ à¤ªà¤°à¤‚à¤¤à¤ªà¥¤ à¤‡à¤®à¤¾à¤‚ à¤šà¤¿à¤¨à¥à¤¤à¤¯à¤¤à¥‹à¤ƒ à¤¸à¤°à¥à¤µà¤¾ à¤¨à¤¿à¤–à¤¿à¤²à¥‡à¤¨ à¤•à¤¥à¤¾à¤‚ à¤¤à¤µà¥¥\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "from datasets import load_dataset\n",
        "import evaluate\n",
        "\n",
        "# Load test dataset\n",
        "ds = load_dataset(\"rahular/itihasa\", split=\"test\")\n",
        "src_texts_raw = [ex[\"translation\"][\"en\"] for ex in ds]\n",
        "tgt_texts = [ex[\"translation\"][\"sn\"] for ex in ds]\n",
        "\n",
        "# Language tags required by IndicTrans2\n",
        "src_lang_tag = \"eng_Latn\"\n",
        "tgt_lang_tag = \"san_Deva\"\n",
        "\n",
        "# Prepend language tags to source text\n",
        "src_texts = [f\"{src_lang_tag} {tgt_lang_tag} {text}\" for text in src_texts_raw]\n",
        "\n",
        "# Load tokenizer and model\n",
        "model_name = \"ai4bharat/indictrans2-en-indic-dist-200M\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name, trust_remote_code=True)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# Load evaluation metrics\n",
        "bleu = evaluate.load(\"bleu\")\n",
        "rouge = evaluate.load(\"rouge\")\n",
        "chrf = evaluate.load(\"chrf\")\n",
        "\n",
        "# Translation function\n",
        "def translate_batch(texts, max_length=128):\n",
        "    inputs = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=max_length)\n",
        "    inputs = inputs.to(model.device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(**inputs,use_cache=False, max_length=max_length, num_beams=5)\n",
        "    return tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "\n",
        "# Batched translation\n",
        "all_preds, all_refs = [], []\n",
        "batch_size = 16\n",
        "\n",
        "for i in range(0, len(src_texts), batch_size):\n",
        "    batch_src = src_texts[i:i + batch_size]\n",
        "    batch_ref = tgt_texts[i:i + batch_size]\n",
        "\n",
        "    preds = translate_batch(batch_src)\n",
        "    all_preds.extend(preds)\n",
        "    all_refs.extend([[ref] for ref in batch_ref])\n",
        "\n",
        "# Strip whitespace\n",
        "all_preds = [p.strip() for p in all_preds]\n",
        "all_refs_flat = [ref[0].strip() for ref in all_refs]\n",
        "\n",
        "# Compute metrics\n",
        "bleu_score = bleu.compute(predictions=all_preds, references=all_refs)[\"bleu\"]\n",
        "rouge_score = rouge.compute(predictions=all_preds, references=all_refs_flat)\n",
        "chrf_score = chrf.compute(predictions=all_preds, references=all_refs_flat)\n",
        "\n",
        "# Results\n",
        "print(\"\\nðŸ“Š IndicTrans2-small on ItihÄsa Test Set:\")\n",
        "print(f\"BLEU:     {bleu_score:.4f}\")\n",
        "print(f\"ROUGE-1:  {rouge_score['rouge1']:.4f}\")\n",
        "print(f\"ROUGE-2:  {rouge_score['rouge2']:.4f}\")\n",
        "print(f\"ROUGE-L:  {rouge_score['rougeL']:.4f}\")\n",
        "print(f\"chrF++:   {chrf_score['score']:.4f}\")\n",
        "\n",
        "# Sample outputs\n",
        "print(\"\\nðŸ” Sample translations:\")\n",
        "for src, ref, pred in zip(src_texts_raw[:3], all_refs_flat[:3], all_preds[:3]):\n",
        "    print(f\"\\nSRC:  {src}\")\n",
        "    print(f\"PRED: {pred}\")\n",
        "    print(f\"REF:  {ref}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'translation': Translation(languages=['sn', 'en'], id=None)}\n",
            "{'en': 'Hearing the words of ViÅ›vÄmitra, RÄghava, together with Laksmana, was struck with amazement, and spoke to ViÅ›vÄmitra, saying,', 'sn': 'à¤µà¤¿à¤¶à¥à¤µà¤¾à¤®à¤¿à¤¤à¥à¤°à¤µà¤šà¤ƒ à¤¶à¥à¤°à¥à¤¤à¥à¤µà¤¾ à¤°à¤¾à¤˜à¤µà¤ƒ à¤¸à¤¹à¤²à¤•à¥à¤·à¥à¤®à¤£à¤ƒà¥¤ à¤µà¤¿à¤¸à¥à¤®à¤¯à¤‚ à¤ªà¤°à¤®à¤‚ à¤—à¤¤à¥à¤µà¤¾ à¤µà¤¿à¤¶à¥à¤µà¤¾à¤®à¤¿à¤¤à¥à¤°à¤®à¤¥à¤¾à¤¬à¥à¤°à¤µà¥€à¤¤à¥à¥¥'}\n"
          ]
        }
      ],
      "source": [
        "print(ds.features)\n",
        "print(ds[0][\"translation\"])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyM+6Jg+2u6YFIgYlVUU8n3Q",
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ashtra_mind",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
