{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM+6Jg+2u6YFIgYlVUU8n3Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Khesorw/AshtraMind/blob/main/IndicTrans2_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ax5UlPwtJXc_"
      },
      "outputs": [],
      "source": [
        "# !pip install transformers sentencepiece evaluate accelerate\n",
        "# !pip install datasets==3.6.0\n",
        "# !pip install rouge_score\n",
        "# !pip install sacrebleu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "from datasets import load_dataset\n",
        "import evaluate\n",
        "\n",
        "# Load test dataset\n",
        "ds = load_dataset(\"rahular/itihasa\", split=\"test\")\n",
        "src_texts_raw = [ex[\"translation\"][\"en\"] for ex in ds]\n",
        "tgt_texts = [ex[\"translation\"][\"sn\"] for ex in ds]\n",
        "\n",
        "# Language tags required by IndicTrans2\n",
        "src_lang_tag = \"eng_Latn\"\n",
        "tgt_lang_tag = \"san_Deva\"\n",
        "\n",
        "# Prepend language tags to source text\n",
        "src_texts = [f\"{src_lang_tag} {tgt_lang_tag} {text}\" for text in src_texts_raw]\n",
        "\n",
        "# Load tokenizer and model\n",
        "model_name = \"ai4bharat/indictrans2-en-indic-dist-200M\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name, trust_remote_code=True)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# Load evaluation metrics\n",
        "bleu = evaluate.load(\"bleu\")\n",
        "rouge = evaluate.load(\"rouge\")\n",
        "chrf = evaluate.load(\"chrf\")\n",
        "\n",
        "# Translation function\n",
        "def translate_batch(texts, max_length=128):\n",
        "    inputs = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=max_length)\n",
        "    inputs = inputs.to(model.device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(**inputs,use_cache=False, max_length=max_length, num_beams=5)\n",
        "    return tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "\n",
        "# Batched translation\n",
        "all_preds, all_refs = [], []\n",
        "batch_size = 16\n",
        "\n",
        "for i in range(0, len(src_texts), batch_size):\n",
        "    batch_src = src_texts[i:i + batch_size]\n",
        "    batch_ref = tgt_texts[i:i + batch_size]\n",
        "\n",
        "    preds = translate_batch(batch_src)\n",
        "    all_preds.extend(preds)\n",
        "    all_refs.extend([[ref] for ref in batch_ref])\n",
        "\n",
        "# Strip whitespace\n",
        "all_preds = [p.strip() for p in all_preds]\n",
        "all_refs_flat = [ref[0].strip() for ref in all_refs]\n",
        "\n",
        "# Compute metrics\n",
        "bleu_score = bleu.compute(predictions=all_preds, references=all_refs)[\"bleu\"]\n",
        "rouge_score = rouge.compute(predictions=all_preds, references=all_refs_flat)\n",
        "chrf_score = chrf.compute(predictions=all_preds, references=all_refs_flat)\n",
        "\n",
        "# Results\n",
        "print(\"\\nüìä IndicTrans2-small on ItihƒÅsa Test Set:\")\n",
        "print(f\"BLEU:     {bleu_score:.4f}\")\n",
        "print(f\"ROUGE-1:  {rouge_score['rouge1']:.4f}\")\n",
        "print(f\"ROUGE-2:  {rouge_score['rouge2']:.4f}\")\n",
        "print(f\"ROUGE-L:  {rouge_score['rougeL']:.4f}\")\n",
        "print(f\"chrF++:   {chrf_score['score']:.4f}\")\n",
        "\n",
        "# Sample outputs\n",
        "print(\"\\nüîç Sample translations:\")\n",
        "for src, ref, pred in zip(src_texts_raw[:3], all_refs_flat[:3], all_preds[:3]):\n",
        "    print(f\"\\nSRC:  {src}\")\n",
        "    print(f\"PRED: {pred}\")\n",
        "    print(f\"REF:  {ref}\")\n"
      ],
      "metadata": {
        "id": "coN8VVHzKTOX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}